{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahekkothari/SLM_Summary/blob/main/SLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Goal: To create a SLM script that summarizes long texts that are written."
      ],
      "metadata": {
        "id": "rrF0tKSDT5rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from heapq import nlargest\n",
        "\n",
        "def summarize_text(text, num_sentences=3):\n",
        "    sentences = sent_tokenize(text) #will tokenize given text into sentences\n",
        "    words = word_tokenize(text.lower()) # will tokenize the text into words\n",
        "\n",
        "\n",
        "    stop_words = set(stopwords.words(\"english\")) # Remove stopwords aka commonly used words\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "\n",
        "    word_freq = FreqDist(words) # finds the frequency of each word in the given text\n",
        "    sentence_scores = {}   # words recieve a score based on word frequency\n",
        "\n",
        "    for sentence in sentences:\n",
        "        for word in word_tokenize(sentence.lower()):\n",
        "            if word in word_freq:\n",
        "                if len(sentence.split(' ')) < 20: #Max amount of words\n",
        "                    if sentence not in sentence_scores:\n",
        "                        sentence_scores[sentence] = word_freq[word]\n",
        "                    else:\n",
        "                        sentence_scores[sentence] += word_freq[word]\n",
        "\n",
        "    # Select the top sentences with the highest scores\n",
        "    summarized_sentences = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "    # Join the selected sentences to create the summary\n",
        "    summary = ' '.join(summarized_sentences)\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xBmwB3OGehNV",
        "outputId": "06da32ba-4ad2-4a3f-f8b9-8d66c03ef9de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "text = \"\"\"\n",
        "If you’ve followed the hype, then you’re likely familiar with LLMs such as ChatGPT. These generative AIs are hugely interesting across academic, industrial and consumer segments. That’s primarily due to their ability to perform relatively complex interactions in the form of speech communication.\n",
        "Currently, LLM tools are being used as an intelligent machine interface to knowledge available on the internet. LLMs distill relevant information on the Internet, which has been used to train it, and provide concise and consumable knowledge to the user. This is an alternative to searching a query on the Internet, reading through thousands of Web pages and coming up with a concise and conclusive answer.\n",
        "Indeed, ChatGPT is the first consumer-facing use case of LLMs, which previously were limited to OpenAI’s GPT and Google’s BERT technology.\n",
        "Recent iterations, including but not limited to ChatGPT, have been trained and engineered on programming scripts. Developers use ChatGPT to write complete program functions – assuming they can specify the requirements and limitations via the text user prompt adequately. (Raza 2024) (https://www.splunk.com/en_us/blog/learn/language-models-slm-vs-llm.html)\n",
        "\"\"\"\n",
        "summary = summarize_text(text)\n",
        "print(\"Summary:\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljOtrVYOqTG5",
        "outputId": "003ee013-4ec2-429c-f634-f1f11c86b722"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "Recent iterations, including but not limited to ChatGPT, have been trained and engineered on programming scripts. \n",
            "If you’ve followed the hype, then you’re likely familiar with LLMs such as ChatGPT. Currently, LLM tools are being used as an intelligent machine interface to knowledge available on the internet.\n"
          ]
        }
      ]
    }
  ]
}